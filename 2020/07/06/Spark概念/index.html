<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><title>Spark专项训练 | 工作随笔</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 4.2.1"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Spark专项训练</h1><a id="logo" href="/.">工作随笔</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Spark专项训练</h1><div class="post-meta">2020-07-06<span> | </span><span class="category"><a href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">Contents</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Spark部署模式"><span class="toc-number">1.</span> <span class="toc-text">Spark部署模式</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#RDD"><span class="toc-number">2.</span> <span class="toc-text">RDD</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#什么是RDD"><span class="toc-number">2.1.</span> <span class="toc-text">什么是RDD</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RDD有什么属性"><span class="toc-number">2.2.</span> <span class="toc-text">RDD有什么属性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RDD弹性表现在那哪些方面"><span class="toc-number">2.3.</span> <span class="toc-text">RDD弹性表现在那哪些方面</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RDD的宽依赖窄依赖，stage划分"><span class="toc-number">2.4.</span> <span class="toc-text">RDD的宽依赖窄依赖，stage划分</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RDD持久化"><span class="toc-number">2.5.</span> <span class="toc-text">RDD持久化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Cache"><span class="toc-number">2.5.1.</span> <span class="toc-text">Cache</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Persist持久化策略"><span class="toc-number">2.5.2.</span> <span class="toc-text">Persist持久化策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Checkpoint"><span class="toc-number">2.5.3.</span> <span class="toc-text">Checkpoint</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#哪些-RDD-需要-checkpoint？"><span class="toc-number">2.5.3.1.</span> <span class="toc-text">哪些 RDD 需要 checkpoint？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#什么时候进行checkpoint"><span class="toc-number">2.5.3.2.</span> <span class="toc-text">什么时候进行checkpoint</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Checkpoint和Cache，Persist区别"><span class="toc-number">2.5.3.3.</span> <span class="toc-text">Checkpoint和Cache，Persist区别</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Checkpoint与Cache的区别"><span class="toc-number">2.5.3.3.1.</span> <span class="toc-text">Checkpoint与Cache的区别</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Checkpoint与Persist区别"><span class="toc-number">2.5.3.3.2.</span> <span class="toc-text">Checkpoint与Persist区别</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Spark工作流"><span class="toc-number">3.</span> <span class="toc-text">Spark工作流</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#提交任务之后发生了什么"><span class="toc-number">3.1.</span> <span class="toc-text">提交任务之后发生了什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark组件作用"><span class="toc-number">3.2.</span> <span class="toc-text">Spark组件作用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#对于-Spark-中的数据倾斜问题你有什么好的方案？"><span class="toc-number">3.3.</span> <span class="toc-text">对于 Spark 中的数据倾斜问题你有什么好的方案？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#什么是数据倾斜"><span class="toc-number">3.3.1.</span> <span class="toc-text">什么是数据倾斜</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据倾斜是如何造成的"><span class="toc-number">3.3.2.</span> <span class="toc-text">数据倾斜是如何造成的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#解决方案"><span class="toc-number">3.3.3.</span> <span class="toc-text">解决方案</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#调整并行度，发生数据倾斜的任务分成多个任务并行执行"><span class="toc-number">3.3.3.1.</span> <span class="toc-text">调整并行度，发生数据倾斜的任务分成多个任务并行执行</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#自定义Partitioner"><span class="toc-number">3.3.3.2.</span> <span class="toc-text">自定义Partitioner</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#将-Reduce-side（侧）-Join-转变为-Map-side（侧）-Join"><span class="toc-number">3.3.3.3.</span> <span class="toc-text">将 Reduce side（侧） Join 转变为 Map side（侧） Join</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#为数据量特别大的-Key-增加随机前-后缀"><span class="toc-number">3.3.3.4.</span> <span class="toc-text">为数据量特别大的 Key 增加随机前&#x2F;后缀</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Shuffle"><span class="toc-number">4.</span> <span class="toc-text">Shuffle</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#什么是Shuffle"><span class="toc-number">4.1.</span> <span class="toc-text">什么是Shuffle</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#如何避免shuffle"><span class="toc-number">4.2.</span> <span class="toc-text">如何避免shuffle</span></a></li></ol></li></ol></div></div><div class="post-content"><h1 id="Spark部署模式"><a href="#Spark部署模式" class="headerlink" title="Spark部署模式"></a>Spark部署模式</h1><ol>
<li>standalone模式，开启7077端口提供服务</li>
<li>spark on yarn模式 ：<ol>
<li>client 模式， driver运行在客户端，调试用 </li>
<li>cluster模式， 分布式运行，driver运行在集群子节点 </li>
</ol>
</li>
</ol>
<a id="more"></a>

<h1 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h1><h2 id="什么是RDD"><a href="#什么是RDD" class="headerlink" title="什么是RDD"></a>什么是RDD</h2><p>弹性分布式数据集（RDD），Spark中的基本抽象。 </p>
<p>代表着一种不可变的，可以被并行操作的集合， 这个类包含RDD所有的基本操作，例如map,filter,perssist</p>
<h2 id="RDD有什么属性"><a href="#RDD有什么属性" class="headerlink" title="RDD有什么属性"></a>RDD有什么属性</h2><p> 一组分片</p>
<p> 一个计算每个分区的函数 </p>
<p> RDD之间的依赖关系 </p>
<p> 一个Partitioner，即RDD的分片函数。 </p>
<p> 一个列表，存储存取每个Partition的优先位置（preferred location） </p>
<h2 id="RDD弹性表现在那哪些方面"><a href="#RDD弹性表现在那哪些方面" class="headerlink" title="RDD弹性表现在那哪些方面"></a>RDD弹性表现在那哪些方面</h2><p> 自动进行磁盘和内存存储的切换 </p>
<p> 基于lineage的高效容错 </p>
<p> task执行失败会进行重试 </p>
<p> stage执行失败会进行重试，并且只重试失败的分片 </p>
<p> checkpoint和persist数据的持久化缓存 </p>
<h2 id="RDD的宽依赖窄依赖，stage划分"><a href="#RDD的宽依赖窄依赖，stage划分" class="headerlink" title="RDD的宽依赖窄依赖，stage划分"></a>RDD的宽依赖窄依赖，stage划分</h2><p>窄依赖： 窄依赖就是指父RDD的每个分区只被一个子RDD分区使用 </p>
<p>宽依赖： 宽依赖就是指父RDD的每个分区都有可能被多个子RDD分区使用， 宽依赖（shuffle）由于依赖的上游RDD不止一个，所以往往需要跨节点传输数据。 </p>
<p>stage： 窄依赖会被划分到同一个Stage中，这样它们就能以管道的方式迭代执行 ， 宽依赖往往对应着shuffle操作，当执行算子有shuffle操作的时候，就划分一个Stage，宽依赖是划分stage的依据 </p>
<p>stage容灾： 窄依赖只需要重新执行父RDD的丢失分区的计算即可恢复。 宽依赖则需要考虑恢复所有父RDD的丢失分区，并且同一RDD下的其他分区数据也重新计算了一次。  ，</p>
<h2 id="RDD持久化"><a href="#RDD持久化" class="headerlink" title="RDD持久化"></a>RDD持久化</h2><h3 id="Cache"><a href="#Cache" class="headerlink" title="Cache"></a>Cache</h3><p>cache是persist(STORAGE_LEVEL=MEMORY_ONLY) </p>
<h3 id="Persist持久化策略"><a href="#Persist持久化策略" class="headerlink" title="Persist持久化策略"></a>Persist持久化策略</h3><p>MEMORY_ONLY ： 使用未序列化的Java对象格式，将数据保存在内存中。如果内存不够存放所有的数据，则数据可能就不会进行持久化。那么下次对这个RDD执行算子操作时，那些没有被持久化的数据，需要从源头处重新计算一遍。这是默认的持久化策略，使用cache()方法时，实际就是使用的这种持久化策略。 </p>
<p>MEMORY_ONLY_SER： 基本含义同MEMORY_ONLY。唯一的区别是，会将RDD中的数据进行序列化，RDD的每个partition会被序列化成一个字节数组。这种方式更加节省内存，从而可以避免持久化的数据占用过多内存导致频繁GC。 </p>
<p>MEMORY_AND_DISK ： 使用未序列化的Java对象格式，优先尝试将数据保存在内存中。如果内存不够存放所有的数据，会将数据写入磁盘文件中，下次对这个RDD执行算子时，持久化在磁盘文件中的数据会被读取出来使用。 </p>
<p>MEMORY_AND_DISK_SER ： 基本含义同MEMORY_AND_DISK。唯一的区别是，会将RDD中的数据进行序列化，RDD的每个partition会被序列化成一个字节数组。这种方式更加节省内存，从而可以避免持久化的数据占用过多内存导致频繁GC。 </p>
<p>DISK_ONLY： 使用未序列化的Java对象格式，将数据全部写入磁盘文件中。 </p>
<p>MEMORY_ONLY_2,MEMORY_AND_DISK_2 ： 对于上述任意一种持久化策略，如果加上后缀_2，代表的是将每个持久化的数据，都复制一份副本，并将副本保存到其他节点上。这种基于副本的持久化机制主要用于进行容错。假如某个节点挂掉，节点的内存或磁盘中的持久化数据丢失了，那么后续对RDD计算时还可以使用该数据在其他节点上的副本。如果没有副本的话，就只能将这些数据从源头处重新计算一遍了。 </p>
<h3 id="Checkpoint"><a href="#Checkpoint" class="headerlink" title="Checkpoint"></a>Checkpoint</h3><h4 id="哪些-RDD-需要-checkpoint？"><a href="#哪些-RDD-需要-checkpoint？" class="headerlink" title="哪些 RDD 需要 checkpoint？"></a>哪些 RDD 需要 checkpoint？</h4><p> 运算时间很长或运算量太大才能得到的 RDD 或是计算链过长或依赖其他 RDD 很多的 RDD </p>
<h4 id="什么时候进行checkpoint"><a href="#什么时候进行checkpoint" class="headerlink" title="什么时候进行checkpoint"></a>什么时候进行checkpoint</h4><p>cache 机制是每计算出一个要 cache 的 partition 就直接将其 cache 到内存了。但 checkpoint 没有类似的方法，而是等到 job 结束后另外启动专门的 job 去完成 checkpoint 。  </p>
<p>因此 checkpoint 的 RDD 会被计算两次。因此，在使用 rdd.checkpoint() 的时候，建议在该语句前面加上 rdd.cache()，这样第二次运行的 job 就不用再去计算该 rdd 了，直接读取 cache 写磁盘。 </p>
<h4 id="Checkpoint和Cache，Persist区别"><a href="#Checkpoint和Cache，Persist区别" class="headerlink" title="Checkpoint和Cache，Persist区别"></a>Checkpoint和Cache，Persist区别</h4><h5 id="Checkpoint与Cache的区别"><a href="#Checkpoint与Cache的区别" class="headerlink" title="Checkpoint与Cache的区别"></a>Checkpoint与Cache的区别</h5><p>cache把 RDD 计算出来然后放在内存中， 但是RDD 的依赖链也不能丢掉， 当某个点某个 executor 宕了， 上面cache 的RDD就会丢掉， 需要通过依赖链重新计算出来；</p>
<p>checkpoint 是把 RDD 保存在 HDFS中， 是多副本可靠存储，所以依赖链就可以丢掉了，就斩断了依赖链，因为checkpoint是需要把 job 重新从头算一遍， 最好先cache一下， checkpoint就可以直接保存缓存中的 RDD 了， 就不需要重头计算一遍了， 对性能有极大的提升。 </p>
<h5 id="Checkpoint与Persist区别"><a href="#Checkpoint与Persist区别" class="headerlink" title="Checkpoint与Persist区别"></a>Checkpoint与Persist区别</h5><p>rdd.persist(StorageLevel.DISK_ONLY) 与 checkpoint 区别的是：前者虽然可以将 RDD 的 partition 持久化到磁盘，但该 partition 由 blockManager 管理。一旦 driver program 执行结束，也就是 executor 所在进程 CoarseGrainedExecutorBackend stop，blockManager 也会 stop，被 cache 到磁盘上的 RDD 也会被清空（整个 blockManager 使用的 local 文件夹被删除）。而 checkpoint 将 RDD 持久化到 HDFS 或本地文件夹，如果不被手动 remove 掉（ 话说怎么 remove checkpoint 过的 RDD？ ），是一直存在的，也就是说可以被下一个 driver program 使用，而 cached RDD 不能被其他 dirver program 使用。 </p>
<h1 id="Spark工作流"><a href="#Spark工作流" class="headerlink" title="Spark工作流"></a>Spark工作流</h1><h2 id="提交任务之后发生了什么"><a href="#提交任务之后发生了什么" class="headerlink" title="提交任务之后发生了什么"></a>提交任务之后发生了什么</h2><ol>
<li><p>构建Spark Application的运行环境（启动SparkContext） </p>
</li>
<li><p>SparkContext向资源管理器（可以是Standalone、Mesos或YARN）注册并申请运行Executor资源； </p>
</li>
<li><p>资源管理器分配Executor资源，Executor运行情况将随着心跳发送到资源管理器上；（yarn会分配worker上的资源，worker将运行情况随心跳发送给executor） </p>
</li>
<li><p>SparkContext构建成DAG图，将DAG图分解成Stage，并把Taskset发送给Task Scheduler </p>
</li>
<li><p>Executor向SparkContext申请Task，Task Scheduler将Task发放给Executor运行，SparkContext将应用程序代码发放给Executor。 </p>
</li>
<li><p>Task在Executor上运行，运行完毕释放所有资源。 </p>
</li>
</ol>
<h2 id="Spark组件作用"><a href="#Spark组件作用" class="headerlink" title="Spark组件作用"></a>Spark组件作用</h2><p>master : 管理节点不参与运算 </p>
<p>worker : 分配任务给executor，向master汇报资源使用情况 </p>
<p>driver : 一个Spark作业运行时包括一个Driver进程，也是作业的主进程，具有main函数，并且有SparkContext的实例，是程序的人口点 , 作用：向集群申请资源，向master注册信息，负责作业调度（生成stage层，并将task任务分配到executor上） </p>
<p>sparkContext : 向yarn申请资源 </p>
<p>client : 提交程序的入口 </p>
<h2 id="对于-Spark-中的数据倾斜问题你有什么好的方案？"><a href="#对于-Spark-中的数据倾斜问题你有什么好的方案？" class="headerlink" title="对于 Spark 中的数据倾斜问题你有什么好的方案？"></a>对于 Spark 中的数据倾斜问题你有什么好的方案？</h2><h3 id="什么是数据倾斜"><a href="#什么是数据倾斜" class="headerlink" title="什么是数据倾斜"></a>什么是数据倾斜</h3><p>对 Spark/Hadoop 这样的大数据系统来讲，数据量大并不可怕，可怕的是数据倾斜。数据倾斜指的是，并行处理的数据集中，某一部分（如 Spark 或 Kafka 的一个 Partition）的数据显著多于其它部分，从而使得该部分的处理速度成为整个数据集处理的瓶颈（木桶效应）。 </p>
<h3 id="数据倾斜是如何造成的"><a href="#数据倾斜是如何造成的" class="headerlink" title="数据倾斜是如何造成的"></a>数据倾斜是如何造成的</h3><p>某个stage中，包含N个task，前N-1个任务执行耗时很短，第N个执行耗时很长，这样导致无法很好利用并行，造成所有任务都在等第N个任务执行完成 </p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="调整并行度，发生数据倾斜的任务分成多个任务并行执行"><a href="#调整并行度，发生数据倾斜的任务分成多个任务并行执行" class="headerlink" title="调整并行度，发生数据倾斜的任务分成多个任务并行执行"></a>调整并行度，发生数据倾斜的任务分成多个任务并行执行</h4><p>Spark 在做 Shuffle 时，默认使用 HashPartitioner对数据进行分区。如果并行度设置的不合适，可能造成大量不相同的 Key 对应的数据被分配到了同一个 Task 上，造成该 Task 所处理的数据远大于其它 Task，从而造成数据倾斜。</p>
<h4 id="自定义Partitioner"><a href="#自定义Partitioner" class="headerlink" title="自定义Partitioner"></a>自定义Partitioner</h4><p>使用自定义的 Partitioner（默认为 HashPartitioner），将原本被分配到同一个 Task 的不同 Key 分配到不同 Task </p>
<h4 id="将-Reduce-side（侧）-Join-转变为-Map-side（侧）-Join"><a href="#将-Reduce-side（侧）-Join-转变为-Map-side（侧）-Join" class="headerlink" title="将 Reduce side（侧） Join 转变为 Map side（侧） Join"></a>将 Reduce side（侧） Join 转变为 Map side（侧） Join</h4><p>通过 Spark 的 Broadcast 机制，将 Reduce 侧 Join 转化为 Map 侧 Join，避免 Shuffle 从而完全消除 Shuffle 带来的数据倾斜。 </p>
<h4 id="为数据量特别大的-Key-增加随机前-后缀"><a href="#为数据量特别大的-Key-增加随机前-后缀" class="headerlink" title="为数据量特别大的 Key 增加随机前/后缀"></a>为数据量特别大的 Key 增加随机前/后缀</h4><p>为数据量特别大的 Key 增加随机前/后缀，使得原来 Key 相同的数据变为 Key 不相同的数据，从而使倾斜的数据集分散到不同的 Task 中，彻底解决数据倾斜问题。Join 另一则的数据中，与倾斜 Key 对应的部分数据，与随机前缀集作笛卡尔乘积，从而保证无论数据倾斜侧倾斜 Key 如何加前缀，都能与之正常 Join。 </p>
<h1 id="Shuffle"><a href="#Shuffle" class="headerlink" title="Shuffle"></a>Shuffle</h1><h2 id="什么是Shuffle"><a href="#什么是Shuffle" class="headerlink" title="什么是Shuffle"></a>什么是Shuffle</h2><p>某种具有共同特征的数据汇聚到一个计算节点上进行计算</p>
<p>另一种说法： 将相同的 Key 分发至同一个 Reducer上进行处理 </p>
<h2 id="如何避免shuffle"><a href="#如何避免shuffle" class="headerlink" title="如何避免shuffle"></a>如何避免shuffle</h2><p>能避免则尽可能避免使用 reduceByKey、join、distinct、repartition 等会进行 shuffle 的算子, 尽量使用 map 类的非 shuffle 算子 </p>
</div><div class="tags"><a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"><i class="fa fa-tag"></i>大数据</a></div><div class="post-nav"><a class="pre" href="/2020/07/06/OOM%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/">常见OOM及原因分析</a><a class="next" href="/2020/07/06/%E4%B8%89%E6%95%B0%E7%9B%B8%E5%8A%A0/">三数之和</a></div><div id="container"></div><link rel="stylesheet" type="text/css" href="//unpkg.com/gitalk/dist/gitalk.css?v=0.0.0"><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=0.0.0"></script><script type="text/javascript" src="//unpkg.com/gitalk/dist/gitalk.min.js?v=0.0.0"></script><script>var gitalk = new Gitalk({
  clientID: '6ac17303e1f9e10122e1',
  clientSecret: '2b166cb9ead4edaac25dc0f9324b03b27cb16ffd',
  repo: 'hexo-comments',
  owner: 'yinxs2003',
  admin: ['yinxs2003'],
  id: md5(location.pathname),
  distractionFreeMode: false
})
gitalk.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a><span class="category-list-count">29</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" style="font-size: 15px;">大数据</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/JVM/" style="font-size: 15px;">JVM</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/jvm/" style="font-size: 15px;">jvm</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 15px;">算法</a> <a href="/tags/%E9%9D%A2%E8%AF%95/" style="font-size: 15px;">面试</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/07/11/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%BB%93%E5%BA%93/">如何搭建个人仓库</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/11/%E9%9D%A2%E8%AF%95-kafka%E4%B8%93%E9%A2%98/">面试-Kafka专题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/10/ambari%E6%98%BE%E7%A4%BAheartbeat_lost%E9%97%AE%E9%A2%98/">Ambari显示heartbeat_lost问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/07/%E6%97%A0%E9%87%8D%E5%A4%8D%E6%9C%80%E9%95%BF%E5%AD%90%E4%B8%B2/">无重复最长子串</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/06/OOM%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/">常见OOM及原因分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/06/Spark%E6%A6%82%E5%BF%B5/">Spark专项训练</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/06/%E4%B8%89%E6%95%B0%E7%9B%B8%E5%8A%A0/">三数之和</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/03/Flink%E7%AA%97%E5%8F%A3/">Flink窗口</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/30/ConcurrentHashMap%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0/">ConcurrentHashMap如何实现的</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/26/Flink%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1/">Flink提交任务</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="http://heqiao2010.github.io/" title="HeQiao的博客" target="_blank">HeQiao的博客</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">工作随笔.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/css/search.css?v=0.0.0"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>